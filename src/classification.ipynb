{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4578405-d08f-40f3-86ae-f1d88d263622",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9dc4032-5942-4d37-85cb-9c05b5bc5519",
   "metadata": {},
   "source": [
    "# Explicit Classification\n",
    "In this notebook, i attempt to classify if songs are explicit or not using the spotify dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956972d2-3187-4146-aa02-436d90fdaef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from data_prep import DataPrep\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac43ad2-621b-461b-9909-69fef7116bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('spotify.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf332b30-fcee-42a3-af03-5ce64751f6a0",
   "metadata": {},
   "source": [
    "### Use DataPrep class to vectorise all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e82ab5b-11c3-4eb4-9e8e-2c369869c6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = DataPrep(df)\n",
    "\n",
    "columns_to_drop=['Artist URI(s)', 'Album URI', 'Album Artist URI(s)',\n",
    "                 'Album Image URL', 'Disc Number', 'Track Preview URL', 'ISRC',\n",
    "                 'Added By', 'Added At', 'Copyrights', 'Album Genres']\n",
    "\n",
    "cat_columns = ['Artist Name(s)','Label','Decade','Key']\n",
    "\n",
    "dp.prepare_data(drop_columns=columns_to_drop,   #columns to remove\n",
    "                cat_columns=cat_columns,        #categorical columns i.e mapping to integer\n",
    "                text_columns=['Track Name','Album Name'], #columns to encode using sent2vec\n",
    "                n_components_text=2)            #number of features to reduce text columns down to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7947881f-3fb6-40e6-9108-1243b2f198e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dp.df\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10000a30-e0b1-4952-9fab-910d50984dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "corr = dp.df.select_dtypes(np.number).corr()\n",
    "fig,ax = plt.subplots(figsize=(12,10))\n",
    "sns.heatmap(corr, cmap='coolwarm', annot=False, fmt=\".1f\", linewidths=0.01)\n",
    "ax.set_title('Correlation Matrix of 9945 Samples with 69 Features')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d118f5b-d110-4696-bf89-af55a3f0439b",
   "metadata": {},
   "source": [
    "### Quick example of classification\n",
    "\n",
    "First lets define all the different types of features + split them into lists, so eventually different features can be compared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d77295-6157-4472-b98e-1deb6d41fb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cross_validation import *\n",
    "from data_loading import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd317d35-62bd-40a9-939f-338b98f33bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable = 'Explicit' #define the variable to classify\n",
    "\n",
    "float_columns = ['Popularity','Track Duration (ms)', 'Explicit', 'Popularity', 'Danceability', 'Energy', 'Key', 'Loudness',\n",
    "                 'Mode', 'Speechiness', 'Acousticness', 'Instrumentalness', 'Liveness','Valence', 'Tempo', 'Time Signature']\n",
    "float_columns = [i for i in float_columns if i!=variable]\n",
    "genre_columns = [i for i in data.columns if 'Genre' in i and i!=variable]\n",
    "album_columns = [i for i in data.columns if 'Album Artist' in i!=variable]\n",
    "cat_columns   = [i for i in cat_columns if i!=variable]\n",
    "text_columns  = [i for i in data.columns if 'Album Name' in i or 'Track Name' in i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90731f0-d210-4ed5-8b66-10c976791953",
   "metadata": {},
   "source": [
    "Define some train test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7e4f30-7079-41c2-aa84-935cb0bdb6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_splits = create_train_test_splits(data, stratified=True,dependent_column=variable,\n",
    "                                             n_splits=1,test_size=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ae0adb-a45e-4b73-adad-5bb5573da43f",
   "metadata": {},
   "source": [
    "Now create train data and test data for this split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fb9293-f49d-46e4-983f-be68a8f9745e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_x, train_y), (test_x, test_y) = get_train_and_test_set(data,train_test_splits[0],\n",
    "                                                              dependent_column=variable,\n",
    "                                                              normalise=True)\n",
    "\n",
    "print(train_x.shape,train_y.shape)\n",
    "print(test_x.shape,test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181fef1c-07e7-4ebc-b39f-64dae0c053d2",
   "metadata": {},
   "source": [
    "Now train a simple model using this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1ab3be-0a2c-46a5-8c6c-5223a9ad3c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "#the model, fit and predict\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(train_x,train_y)\n",
    "predict = model.predict(test_x)\n",
    "\n",
    "print('acc:',accuracy_score(test_y,predict))\n",
    "print('f1:',f1_score(test_y,predict,average='macro'))\n",
    "precision_score(test_y,predict,average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d1066f-0742-4ead-9f6d-fdff0dc9a4ec",
   "metadata": {},
   "source": [
    "Lets run cross validation to get a better understanding and compare lots of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e4ff34-b39c-4e44-ba07-a135bdb2c113",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier,AdaBoostClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb820c67-37c7-4cba-be32-69255d4b48b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "architectures = [XGBClassifier,DecisionTreeClassifier,RandomForestClassifier,ExtraTreesClassifier,AdaBoostClassifier]\n",
    "normalise     = [True, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece0630b-88aa-4395-8350-d0f4cc61f510",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_splits = create_train_test_splits(data, stratified=True,dependent_column=variable,\n",
    "                                             n_splits=10,test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b847cc7b-f0fe-443a-a714-b162a1f45290",
   "metadata": {},
   "outputs": [],
   "source": [
    "reports = []\n",
    "#loop through architectures\n",
    "for arch in tqdm(architectures):\n",
    "    #loop through normalisation options\n",
    "    for norm in normalise:\n",
    "        #train same architecture n_splits times and average the results\n",
    "        report = perform_cross_validation(dataset=data,\n",
    "                                          architecture=arch,\n",
    "                                          splits=train_test_splits,\n",
    "                                          dependent_column=variable,\n",
    "                                          normalise=norm)\n",
    "        reports.append(report)\n",
    "\n",
    "results = pd.DataFrame(reports)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb536741-8a10-43b7-b323-6d20c32f0966",
   "metadata": {},
   "source": [
    "results is a dataframe containing the classification metrics; essentially, the models largely perform the same regardless of normalisation. Explicit is a different field to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5363ccc-cfd6-47c8-bf92-62670eeac09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_copy = results.copy()\n",
    "results_copy = results_copy.sort_values(by='f1 mean',ascending=False)\n",
    "results_copy = results_copy[['arch','normalise','f1 mean', 'f1 std', 'acc mean', 'acc std']]\n",
    "results_copy['f1'] = [f'{i:.3f} ± {j:.3f}' for i,j in results_copy[['f1 mean','f1 std']].values]\n",
    "results_copy['acc'] = [f'{i:.3f} ± {j:.3f}' for i,j in results_copy[['acc mean','acc std']].values]\n",
    "results_copy.drop(columns=['f1 mean', 'f1 std', 'acc mean', 'acc std']).reset_index(drop=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58cf93c-7c76-49f5-990b-1d23eb7bbe68",
   "metadata": {},
   "source": [
    "### Varying the Features\n",
    "it could be that some features hurt the classification. Lets look at the feature importance for the original decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503c4633-0580-4f75-b1c9-338407e0fa15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig,ax = plt.subplots(figsize=(5,3))\n",
    "names  = [i for i in data.columns if i not in [variable,'Track URI']]\n",
    "imp    = model.feature_importances_\n",
    "asort  = imp.argsort()[::-1]\n",
    "imp    = imp[asort][:20]\n",
    "names  = np.array(names)[asort][:20]\n",
    "ax.scatter(np.arange(1,len(imp)+1),imp,zorder=10,edgecolor='k',s=50)\n",
    "ax.set_xticks(np.arange(1,len(imp)+1))\n",
    "ax.set_xticklabels(names,rotation=90)\n",
    "ax.set_ylabel('Importance')\n",
    "ax.set_title('Top 20 most important features for \"Explicit\" Classification')\n",
    "ax.grid(zorder=-1)\n",
    "fig.tight_layout()\n",
    "fig.set_dpi(150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ca57bc-a048-47e3-b5f7-55e9be294328",
   "metadata": {},
   "source": [
    "Select to top-20 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6c0fe7-3699-485b-bb6e-141ea84725bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "top20       = np.argsort(imp,)[::-1][:20]\n",
    "cols        = [names[i] for i in top20] + [variable,'Track URI']\n",
    "data_top20  = dp.df[cols]\n",
    "\n",
    "train_test_splits = create_train_test_splits(data, stratified=True,dependent_column=variable,\n",
    "                                             n_splits=10,test_size=0.50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2495cd5-511e-4a1e-91af-301de6f1ab9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "top20_reports = []\n",
    "#loop through architectures\n",
    "for arch in tqdm(architectures):\n",
    "    #loop through normalisation options\n",
    "    for norm in normalise:\n",
    "        #train same architecture n_splits times and average the results\n",
    "        report = perform_cross_validation(dataset=data_top20,\n",
    "                                          architecture=arch,\n",
    "                                          splits=train_test_splits,\n",
    "                                          dependent_column=variable,\n",
    "                                          normalise=norm)\n",
    "        top20_reports.append(report)\n",
    "\n",
    "top20_results = pd.DataFrame(top20_reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991d0d18-264c-43f1-9d49-552b9384fb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "top20_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979e2a23-22e0-44cb-86d3-bfc804ba1f62",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c546dbb8-654c-46a3-8a66-78abbaab73ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "cm = ConfusionMatrixDisplay(results['cm mean'].values[0])\n",
    "fig,ax = plt.subplots(figsize=(3,3))\n",
    "cm.plot(ax=ax)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9755c4d8-9655-407a-b059-a744ff073bcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
